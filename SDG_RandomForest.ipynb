{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95dece62-ca9c-42e1-840a-982159d84129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_original = pd.read_csv(\"D:/Portfolio/eu_sdg_performance_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f694f7-5237-4a1d-af82-3fbb5e7abaa0",
   "metadata": {},
   "source": [
    "We will provide a description of the variables included in the dataset in accordance with the methodology of the Europe Sustainable Development Report 2025 (ESDR2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3863f76-e3c9-4f90-9078-d2bd063c874d",
   "metadata": {},
   "source": [
    "| Variable              | Description                                                    | Unit in dataset                                 |\n",
    "| --------------------- | -------------------------------------------------------------- | ----------------------------------------------- |\n",
    "| **year**              | Year of observation                                            | year (2015–2024)                                |\n",
    "| **sdgi\\_score**       | Overall SDG Index (aggregate sustainability performance score) | scale 0–100                                     |\n",
    "| **performance\\_tier** | Sustainability performance classification                      | 0 = Needs Improvement, 1 = Good, 2 = Leaders    |\n",
    "| **sdg8\\_income**      | Average income per capita (GDP per capita, PPP)                | € per person (≈ 8,800 – 39,000)                 |\n",
    "| **sdg8\\_unemp**       | Unemployment rate                                              | % of population (2 – 26%)                       |\n",
    "| **sdg8\\_inwork**      | Employment-to-population ratio                                 | % of population (3 – 19%)                       |\n",
    "| **sdg9\\_eurd**        | Expenditure on R\\&D                                            | % of GDP (0 – 4%)                               |\n",
    "| **sdg9\\_digital**     | Basic digital skills of the population                         | % of population (28 – 83%)                      |\n",
    "| **sdg9\\_bband**       | Broadband internet coverage                                    | % of households (59 – 100%)                     |\n",
    "| **sdg16\\_cpi**        | Corruption Perception Index (Transparency International)       | scale 0–100 (34 – 91; higher = less corruption) |\n",
    "| **sdg16\\_rsf**        | Press Freedom Index (Reporters Without Borders)                | scale 0–100 (32 – 95; higher = freer press)     |\n",
    "| **sdg16\\_crime**      | Crime/Safety index                                             | normalized index 1–26 (lower = less crime)      |\n",
    "| **sdg4\\_tertiary**    | Population with tertiary education                             | % of adults (23 – 63%)                          |\n",
    "| **sdg4\\_adult**       | Adult participation in education/training                      | % of adults (1 – 39%)                           |\n",
    "| **sdg7\\_eurenew**     | Share of renewable energy in final energy consumption          | % (5 – 84%)                                     |\n",
    "| **sdg13\\_co2gcp**     | CO₂ emissions per capita                                       | tons CO₂ per person (≈ 3 – 16.6)                |\n",
    "| **sdg5\\_empgap**      | Gender employment gap                                          | % difference between men and women (0 – 43%)    |\n",
    "| **sdg10\\_gini**       | Gini coefficient (income inequality)                           | 21 – 45 (scale typical for Europe)              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad77edc-6c94-44ea-9e21-61efc0260fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Austria'\n",
      "'Baltic States'\n",
      "'Belgium'\n",
      "'Bulgaria'\n",
      "'Candidate Countries'\n",
      "'Central and Eastern Europe'\n",
      "'Croatia'\n",
      "'Cyprus'\n",
      "'Czechia'\n",
      "'Denmark'\n",
      "'EFTA Countries'\n",
      "'Estonia'\n",
      "'European Union'\n",
      "'Finland'\n",
      "'France'\n",
      "'Germany'\n",
      "'Greece'\n",
      "'Hungary'\n",
      "'Iceland'\n",
      "'Ireland'\n",
      "'Italy'\n",
      "'Latvia'\n",
      "'Lithuania'\n",
      "'Luxembourg'\n",
      "'Malta'\n",
      "'Netherlands'\n",
      "'North Macedonia'\n",
      "'Northern Europe'\n",
      "'Norway'\n",
      "'Poland'\n",
      "'Portugal'\n",
      "'Romania'\n",
      "'Serbia'\n",
      "'Slovak Republic'\n",
      "'Slovenia'\n",
      "'Southern Europe'\n",
      "'Spain'\n",
      "'Sweden'\n",
      "'Switzerland'\n",
      "'TŸrkiye'\n",
      "'United Kingdom'\n",
      "'Western Europe'\n"
     ]
    }
   ],
   "source": [
    "countries = sorted(df_original[\"Country\"].unique())\n",
    "for c in countries:\n",
    "    print(repr(c)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a36258-7035-46b1-b4ab-5a78f5bcbbc4",
   "metadata": {},
   "source": [
    "In the original dataset, the Country column contained a mix of individual nations (e.g., Germany, Poland, Romania) and regional aggregations (European Union, Baltic States, Candidate Countries). \n",
    "\n",
    "Potential problems:\n",
    "1. Inconsistent Granularity: the dataset contains information at two different levels of detail: individual countries (low aggregation) and regional groups (high aggregation). This inconsistency can distort the analysis, as the model would be trained on data with varying levels of granularity.\n",
    "2. Alignment with Project Goal: the main project goal is to classify individual European countries. Including aggregated data that describes regional groups contradicts this objective. Removing this data ensures the model focuses exclusively on the features relevant to classifying individual nations.\n",
    "3. Bias: aggregated data represents average indicators for entire regions and does not reflect the unique characteristics of any single country. Using it can introduce bias, as the model would be trained on \"hybrid\" data points that are not representative of the real classification subjects.\n",
    "\n",
    "Removing aggregated data simplifies the model and makes it more understandable. This allows us to be confident that the conclusions we draw from the model (for example, identifying key factors influencing the classification) truly relate to individual countries and not to the averaged characteristics of entire regions. This makes our results more reliable and meaningful for decision-making.\n",
    "\n",
    "After cleaning, 34 countries remained (approximately 81% of all rows). This provides a sufficient base for modeling and makes the results more accurate and reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24030341-182a-40b5-8965-569d6a5f9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_to_exclude = [\n",
    "    'Baltic States',\n",
    "    'Candidate Countries',\n",
    "    'Central and Eastern Europe',\n",
    "    'EFTA Countries',\n",
    "    'European Union',\n",
    "    'Northern Europe',\n",
    "    'Southern Europe',\n",
    "    'Western Europe'\n",
    "]\n",
    "df= df_original[~df_original['Country'].isin(regions_to_exclude)].copy()\n",
    "df_regions = df_original[df_original['Country'].isin(regions_to_exclude)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd077871-7ba5-4c93-9523-0523598469b7",
   "metadata": {},
   "source": [
    "Replace the county's name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a7fec3-45a4-4ebe-b6c5-da056323f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Country\"] = df[\"Country\"].replace(\"TŸrkiye\", \"Turkey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a226a-e303-4d9f-90b9-e28bf83bbc9a",
   "metadata": {},
   "source": [
    "For the following analysis, we need to properly impute all NaN values.\n",
    "Let's find the number of NaN values and the countries/columns that contain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d152065-e5a7-458a-928e-985e8476c48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 340 entries, 0 to 409\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Country           340 non-null    object \n",
      " 1   year              340 non-null    int64  \n",
      " 2   sdgi_score        340 non-null    float64\n",
      " 3   performance_tier  340 non-null    int64  \n",
      " 4   sdg8_income       330 non-null    float64\n",
      " 5   sdg8_unemp        330 non-null    float64\n",
      " 6   sdg8_inwork       340 non-null    int64  \n",
      " 7   sdg9_eurd         340 non-null    int64  \n",
      " 8   sdg9_digital      330 non-null    float64\n",
      " 9   sdg9_bband        340 non-null    int64  \n",
      " 10  sdg16_cpi         340 non-null    int64  \n",
      " 11  sdg16_rsf         340 non-null    int64  \n",
      " 12  sdg16_crime       340 non-null    int64  \n",
      " 13  sdg4_tertiary     340 non-null    int64  \n",
      " 14  sdg4_adult        340 non-null    int64  \n",
      " 15  sdg7_eurenew      310 non-null    float64\n",
      " 16  sdg13_co2gcp      340 non-null    float64\n",
      " 17  sdg5_empgap       330 non-null    float64\n",
      " 18  sdg10_gini        340 non-null    int64  \n",
      "dtypes: float64(7), int64(11), object(1)\n",
      "memory usage: 53.1+ KB\n",
      "None\n",
      "\n",
      "NaN per column:\n",
      " Country              0\n",
      "year                 0\n",
      "sdgi_score           0\n",
      "performance_tier     0\n",
      "sdg8_income         10\n",
      "sdg8_unemp          10\n",
      "sdg8_inwork          0\n",
      "sdg9_eurd            0\n",
      "sdg9_digital        10\n",
      "sdg9_bband           0\n",
      "sdg16_cpi            0\n",
      "sdg16_rsf            0\n",
      "sdg16_crime          0\n",
      "sdg4_tertiary        0\n",
      "sdg4_adult           0\n",
      "sdg7_eurenew        30\n",
      "sdg13_co2gcp         0\n",
      "sdg5_empgap         10\n",
      "sdg10_gini           0\n",
      "dtype: int64\n",
      "\n",
      "Total number of NaN: 70\n",
      "\n",
      "Countries with missing values (NaN):\n",
      "\tNorth Macedonia: ['sdg8_income']\n",
      "\tSwitzerland: ['sdg7_eurenew']\n",
      "\tTurkey: ['sdg7_eurenew']\n",
      "\tUnited Kingdom: ['sdg8_unemp', 'sdg9_digital', 'sdg7_eurenew', 'sdg5_empgap']\n",
      "\n",
      "Columns with missing values (NaN): ['sdg8_income', 'sdg8_unemp', 'sdg9_digital', 'sdg7_eurenew', 'sdg5_empgap']\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "\n",
    "nan_per_column = df.isnull().sum()\n",
    "print(\"\\nNaN per column:\\n\", nan_per_column)\n",
    "\n",
    "total_nan = df.isnull().sum().sum()\n",
    "print(\"\\nTotal number of NaN:\", total_nan)\n",
    "\n",
    "missing_dict = (\n",
    "    df.drop(columns=[\"Country\"])\n",
    "      .groupby(df[\"Country\"])\n",
    "      .apply(lambda g: g.isna().any()[lambda x: x].index.tolist())\n",
    "      .to_dict()\n",
    ") \n",
    "missing_nonempty = {k: v for k, v in missing_dict.items() if v}\n",
    "print(\"\\nCountries with missing values (NaN):\")\n",
    "for country, cols in missing_nonempty.items():\n",
    "    print(f\"\\t{country}: {cols}\")\n",
    "\n",
    "cols_with_nan = df.columns[df.isna().any()].tolist()\n",
    "print(\"\\nColumns with missing values (NaN):\", cols_with_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0ed458-a7e3-419f-99ca-193a441982c2",
   "metadata": {},
   "source": [
    "Unfortunately, we cannot use real data from other sources (the World Bank or Eurostat), as the research methodologies differ and the required data are simply unavailable.\n",
    "That's why we will follow the strategy: imputation will be based on the regional mean.\n",
    "\n",
    "df — the main dataset with individual countries\n",
    "df_regions — the dataset with aggregated groups (Candidate Countries, EFTA Countries, ...). \n",
    "\n",
    "The df_regions subset already contains averaged indicators for the corresponding country groups; therefore, during imputation we will substitute the values for the respective year from the appropriate group:\n",
    "\n",
    "North Macedonia → Candidate Countries \n",
    "Switzerland → EFTA Countries\n",
    "Turkey → Candidate Countries\n",
    "United Kingdom → Western Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f95dbc38-4772-4520-921d-19e0b8a27cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0tal number of NaN:\n"
     ]
    }
   ],
   "source": [
    "#This dictionary defines the mapping between an individual country and its corresponding aggregated group (union).\n",
    "union_map = {\n",
    "    'North Macedonia': 'Candidate Countries',\n",
    "    'Switzerland': 'EFTA Countries',\n",
    "    'Turkey': 'Candidate Countries',\n",
    "    'United Kingdom': 'Western Europe',\n",
    "}\n",
    "#  missing_nonempty -  this dictionary specifies which variables are missing for each country\n",
    "\n",
    "#We will create new function impute_from_unions\n",
    "def impute_from_unions(df, df_regions, union_map, missing_nonempty,\n",
    "                       country_col='Country', year_col='year'):\n",
    "    out = df.copy()\n",
    "    for country, cols in missing_nonempty.items():\n",
    "        union = union_map.get(country)\n",
    "        if not union:\n",
    "            continue\n",
    "        for col in cols:\n",
    "            if col not in out.columns or col not in df_regions.columns:\n",
    "                continue\n",
    "            # серія рік -> значення з union/aggregated group\n",
    "            union_series = (\n",
    "                df_regions[df_regions[country_col] == union][[year_col, col]]\n",
    "                .dropna()\n",
    "                .set_index(year_col)[col]\n",
    "            )\n",
    "            if union_series.empty:\n",
    "                continue\n",
    "            mask = (out[country_col] == country) & (out[col].isna())\n",
    "            out.loc[mask, col] = out.loc[mask, year_col].map(union_series)\n",
    "    return out\n",
    "\n",
    "\n",
    "df = impute_from_unions(df, df_regions, union_map, missing_nonempty)\n",
    "\n",
    "#Let's revise the results of data preprocessing\n",
    "total_nan = df.isnull().sum().sum()\n",
    "print(\"\\nTotal number of NaN:\", total_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7664338-1603-47ab-8785-9f39e8c35089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest (RandomizedSearch) ===\n",
      "Best params: {'rf__max_depth': 11, 'rf__max_features': None, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 900}\n",
      "CV best f1_weighted: 0.9418263191846211\n",
      "Test Accuracy: 0.9607843137254902\n",
      "Test F1 (weighted): 0.9600802729891631\n",
      "\n",
      "Confusion matrix:\n",
      " [[18  3  0]\n",
      " [ 0 65  0]\n",
      " [ 0  1 15]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92        21\n",
      "           1       0.94      1.00      0.97        65\n",
      "           2       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.96       102\n",
      "   macro avg       0.98      0.93      0.95       102\n",
      "weighted avg       0.96      0.96      0.96       102\n",
      "\n",
      "\n",
      "Top-10 RF feature importances:\n",
      "sdg9_digital     0.382087\n",
      "sdg16_cpi        0.197545\n",
      "sdg9_eurd        0.088927\n",
      "sdg4_tertiary    0.064170\n",
      "sdg7_eurenew     0.055871\n",
      "sdg16_rsf        0.048062\n",
      "sdg13_co2gcp     0.039375\n",
      "sdg10_gini       0.039187\n",
      "sdg9_bband       0.028286\n",
      "sdg5_empgap      0.022279\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from scipy.stats import randint\n",
    "\n",
    "# 1) Завантаження даних\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# 2) X / y\n",
    "X = df.drop(columns=[\"performance_tier\", \"sdgi_score\", \"Country\", \"year\"], errors=\"ignore\")\n",
    "y = df[\"performance_tier\"]\n",
    "\n",
    "# 3) Train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Random Forest + RandomizedSearch\n",
    "pipe_rf = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"rf\", RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_dist_rf = {\n",
    "    \"rf__n_estimators\": randint(300, 1200),\n",
    "    \"rf__max_depth\": randint(3, 50),\n",
    "    \"rf__min_samples_split\": randint(2, 20),\n",
    "    \"rf__min_samples_leaf\": randint(1, 10),\n",
    "    \"rf__max_features\": [\"sqrt\", \"log2\", None],\n",
    "    # \"rf__class_weight\": [None, \"balanced\", \"balanced_subsample\"],  # опційно\n",
    "}\n",
    "\n",
    "rs_rf = RandomizedSearchCV(\n",
    "    pipe_rf, param_distributions=param_dist_rf, n_iter=50,\n",
    "    cv=cv, scoring=\"f1_weighted\", n_jobs=-1, random_state=42, refit=True\n",
    ")\n",
    "\n",
    "# 5) Навчання\n",
    "rs_rf.fit(X_train, y_train)\n",
    "y_pred_rf = rs_rf.predict(X_test)\n",
    "\n",
    "# 6) Результати\n",
    "print(\"=== Random Forest (RandomizedSearch) ===\")\n",
    "print(\"Best params:\", rs_rf.best_params_)\n",
    "print(\"CV best f1_weighted:\", rs_rf.best_score_)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Test F1 (weighted):\", f1_score(y_test, y_pred_rf, average=\"weighted\"))\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# 7) Топ-важливості ознак\n",
    "final_rf = rs_rf.best_estimator_.named_steps[\"rf\"]\n",
    "importances = pd.Series(final_rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"\\nTop-10 RF feature importances:\")\n",
    "print(importances.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c7026-aa39-49ff-8378-ecd237fd779d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
